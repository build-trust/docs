---
title: "Agents"
icon: "star-shooting"
description: "Ockam Agents are intelligent autonomous actors."
---

Python apps running in Ockam AI can create millions of collaborating agents. Ockam Agents are autonomous actors that accomplish complex open ended tasks. Each Agent:

- Has a unique identity.
- Uses a large language model to understand natual language.
- Has memory of conversations.
- Can reason and plan to break down complex tasks.
- Can retrieve information beyond the training data of its language model.
- Can invoke tools to access information and take actions.
- Can collaborate with and delegate work to other agents.

<RequestExample>

```python images/main/main.py
from ockam import Agent, Node


async def main(node):
    await Agent.start(
        node=node,
        name="henry",
        instructions="""
            You are Henry, an expert legal assistant.
        """
    )


Node.start(main)
```

</RequestExample>

<Tip>
  You can find all the code for this example [on Github](https://github.com/build-trust/ockam/tree/develop/examples/001).
</Tip>

```yaml ockam.yaml
name: 01
pods:
  - name: main-pod
    public: true
    containers:
      - name: main
        image: main
```

There are three key files that define an agent. First is the `ockam.yaml` file:

The `ockam.yaml` file above defines:

- `name: 01` - A unique name for this deployment zone
- `pods` - A list of pods to run in the zone
  - `name: main-pod` - The name of the pod
  - `public: true` - Makes the pod accessible from the internet
  - `containers` - The containers to run in the pod
    - `name: main` - Container name
    - `image: main` - References the image built from the `Dockerfile` located at `images/<value>/Dockerfile`

This minimal configuration creates a deployment that runs our agent code.

Next is the `Dockerfile` file:

```bash images/main/Dockerfile
FROM ghcr.io/build-trust/ockam-python:latest
COPY . .
ENTRYPOINT ["python", "main.py"]
```

The `Dockerfile` above:

- Uses the official Ockam Python base image which includes the Ockam SDK
- Copies the agent code (main.py and other files) into the container
- Sets the entrypoint to run main.py when the container starts

Finally is the `main.py` file:

```python images/main/main.py
from ockam import Agent, Node


async def main(node):
    await Agent.start(node, "You are Henry, an expert legal assistant", "henry")


Node.start(main)
```

The `main.py` file above:

- Imports the Ockam SDK
- Defines an async main function that starts an agent with a specific prompt
- Starts the node and agent

<Note>
  Ensure you have [Docker](https://www.docker.com/get-started/) installed and running on your workstation before running the `ockam` command.
</Note>

When you run `ockam` it will:

- Build the image from the Dockerfile
- Deploy the container to the Ockam serverless runtime
- Expose a public HTTP endpoint to the agent
- Create two local (i.e., on your workstation) portals to the agent's HTTP endpoint and log output.

```[expandable]
» ockam
    Deploying zone 01 in cluster 25df35de87aa441b88f22a6c2a830a17...

  ✔ Created a repository for the image main
  ✔ Built image main
  ✔ Pushed image main

  ✔ Deployed zone 01 in cluster 25df35de87aa441b88f22a6c2a830a17

    The http server on the main-pod is available at:
    https://25df35de87aa441b88f22a6c2a830a17-01.ai.ockam.network

  ✔ Opened a portal to the outlet http on main-pod from tcp://localhost:8000
  ✔ Opened a portal to the outlet logs on logs-pod from tcp://localhost:3000

    ─────────────────────────────────────────────────
    Press Ctrl+C to stop all portals and exit
```

## Arguments

- `name`
- `node`
- `instructions`
- `model`
- `knowledge`
- `tools`
- `max_knowledge_size`
- `planner`
- `exposed_as`

### Instance arguments

- `prompt`
- `scope`
- `conversation`

## Logs

You can see the logs of your running python app on `http://localhost:3000/logs/explorer` .

## HTTP Server

By default the pod will expose a HTTP interface with a few endpoints interact with the deployed agents.

### List agents

The public URL for the HTTP server on your pod (each pod will have its own unique URL) is displayed in the example output above:

> The http server on the main-pod is available at:
> https://25df35de87aa441b88f22a6c2a830a17-01.ai.ockam.network

To return a list of all agents running on that pod send a `GET` request to the `/agents` endpoint:

<CodeGroup>

```bash httpie
http GET \
"https://25df35de87aa441b88f22a6c2a830a17-01.ai.ockam.network/agents"
```


```bash curl
curl --request GET \
"https://25df35de87aa441b88f22a6c2a830a17-01.ai.ockam.network/agents"
```

</CodeGroup>

```json response
{
    "agents": [
        {
            "description": [],
            "is_remote": false,
            "name": "ef48fd1c0b8f342ef12bf679",
            "workers": []
        }
    ]
}
```

### Send prompt to agent

To interact with a specific agent, send a `POST` request to the `/agents/<name>` endpoint:

<CodeGroup>

```bash httpie
http POST \
  "https://25df35de87aa441b88f22a6c2a830a17-example001.ai.ockam.network/agents/ef48fd1c0b8f342ef12bf679" \
  message="who are you"
```


```bash curl
curl --request POST \
  --header "Content-Type: application/json" \
  --data '{"message":"who are you"}' \
  "https://25df35de87aa441b88f22a6c2a830a17-example001.ai.ockam.network/agents/ef48fd1c0b8f342ef12bf679"
```

</CodeGroup>

```json response

[
    {
        "content": "(in a pirate accent) Ah, I be Captain Jack Sparrow, the infamous pirate of the Seven Seas. Me reputation precedes me, savvy? I be the master of me own ship, the Black Pearl, the fastest vessel to ever sail the Caribbean. Me cunning and me wit be me greatest treasures, and me ability to talk me way out o' trouble be me most prized possession.\n\nI've had me share o' adventures, battled the Royal Navy, and outwitted the scurvy dog, Captain Barbossa. Me exploits be the stuff o' legend, and me name be whispered in fear and awe by all who sail the seas.\n\nSo, what be bringin' ye to these waters? Are ye lookin' to join me crew, or are ye just lookin' to get yerself into a bit o' trouble? Either way, I be happy to oblige, matey.",
        "role": "assistant",
        "tool_calls": []
    }
]
```

### Send prompt to agent (\+ stream response)

For some use cases, especially user-facing ones with potentially long responses, it may be preferable to stream the response. Passing a `stream=true` parameter to the `/agents/<name>` endpoint will stream chunked responses from the agent in real-time:

<CodeGroup>

```bash httpie
http POST \
"https://25df35de87aa441b88f22a6c2a830a17-01.ai.ockam.network/agents/ef48fd1c0b8f342ef12bf679?stream=true" \
message="what is a patent"
```


```bash curl
curl --request POST \
--header "Content-Type: application/json" \
--data '{"message": "what is a patent"}' \
"https://25df35de87aa441b88f22a6c2a830a17-01.ai.ockam.network/agents/ef48fd1c0b8f342ef12bf679?stream=true"
```

</CodeGroup>

```json response

{"scope": "None", "conversation": "None", "messages": [{"content": "(smirking) Ah, ye want to know who I be again, eh? Alright", "role": "assistant", "tool_calls": []}], "type": "conversation_snippet"}
{"scope": "None", "conversation": "None", "messages": [{"content": " then, matey. I be Captain Jack Sparrow, the one and", "role": "assistant", "tool_calls": []}], "type": "conversation_snippet"}
{"scope": "None", "conversation": "None", "messages": [{"content": " only. Me life be a tale of piracy, adventure, and a", "role": "assistant", "tool_calls": []}], "type": "conversation_snippet"}
{"scope": "None", "conversation": "None", "messages": [{"content": " wee bit o' luck. I've sailed the Seven Seas, discovered", "role": "assistant", "tool_calls": []}], "type": "conversation_snippet"}
{"scope": "None", "conversation": "None", "messages": [{"content": " hidden treasure, and battled the scurviest of scound", "role": "assistant", "tool_calls": []}], "type": "conversation_snippet"}
{"scope": "None", "conversation": "None", "messages": [{"content": "rels.\n\nMe skills be many: I be a master swordsman, a", "role": "assistant", "tool_calls": []}], "type": "conversation_snippet"}
{"scope": "None", "conversation": "None", "messages": [{"content": " cunning strategist, and a charismatic negotiator. Me", "role": "assistant", "tool_calls": []}], "type": "conversation_snippet"}
{"scope": "None", "conversation": "None", "messages": [{"content": " ship, the Black Pearl, be me pride and joy, and me", "role": "assistant", "tool_calls": []}], "type": "conversation_snippet"}
{"scope": "None", "conversation": "None", "messages": [{"content": " loyal crew be me family.\n\nBut, I be more than just", "role": "assistant", "tool_calls": []}], "type": "conversation_snippet"}
{"scope": "None", "conversation": "None", "messages": [{"content": " a pirate, matey. I be a free spirit, a rebel, and a", "role": "assistant", "tool_calls": []}], "type": "conversation_snippet"}
{"scope": "None", "conversation": "None", "messages": [{"content": " trickster. I live by me own rules, and I never back", "role": "assistant", "tool_calls": []}], "type": "conversation_snippet"}
{"scope": "None", "conversation": "None", "messages": [{"content": " down from a challenge. Me motto be \"Savvy?\" \u2013 and I", "role": "assistant", "tool_calls": []}], "type": "conversation_snippet"}
{"scope": "None", "conversation": "None", "messages": [{"content": " always be lookin' for the next great adventure.\n\nSo", "role": "assistant", "tool_calls": []}], "type": "conversation_snippet"}
{"scope": "None", "conversation": "None", "messages": [{"content": ", now ye know who I be. What be yer business with me", "role": "assistant", "tool_calls": []}], "type": "conversation_snippet"}
{"scope": "None", "conversation": "None", "messages": [{"content": ", matey?", "role": "assistant", "tool_calls": []}], "type": "conversation_snippet"}
```